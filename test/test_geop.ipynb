{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from datetime import datetime\n",
    "# might be a problem for ML data, since the data is quite large in size\n",
    "# Define a function to open datasets and concatenate them\n",
    "def open_and_concatenate(year, variable, months, way, level=0):\n",
    "    datasets = []\n",
    "    for month in months:\n",
    "        dataset = xr.open_dataset(f'{way}{variable}/ERA5_{year}-{month}_{variable}.nc')\n",
    "        if variable == 'geopotential' and level != 0:\n",
    "            dataset = dataset.sel(level=level)\n",
    "        \n",
    "        # Create a date range with 3-hour intervals starting from midnight\n",
    "        start = pd.Timestamp(f\"{year}-{month}-01 00:00:00\")\n",
    "        if month == 12:\n",
    "            end = pd.date_range(start=f\"{year}-{month}-01\", end=f\"{str(int(year)+1)}-01-01\", freq='M')[0] + pd.Timedelta(hours=21)\n",
    "        else:\n",
    "            end = pd.date_range(start=f\"{year}-{month}-01\", end=f\"{year}-{month+1}-01\", freq='M')[0] + pd.Timedelta(hours=21)\n",
    "        date_range = pd.date_range(start, end, freq='3H')\n",
    "\n",
    "        # Select the data at the specific timesteps\n",
    "        dataset = dataset.sel(time=date_range)\n",
    "        \n",
    "        datasets.append(dataset)\n",
    "        dataset.close()\n",
    "\n",
    "    return xr.concat(datasets, dim='time')\n",
    "\n",
    "# Define a function to calculate statistics\n",
    "def calculate_statistics(data_array):\n",
    "    return {\n",
    "        'mean': np.mean(data_array),\n",
    "        'min': np.min(data_array),\n",
    "        'max': np.max(data_array),\n",
    "        'std': np.std(data_array),\n",
    "    }\n",
    "\n",
    "# Function to log processing details\n",
    "def log_processing(variable, year, level, storm_number):\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    log_message = f'Processed variable: {variable}, Year: {year}, Level: {level}, Timestamp: {timestamp}, Storm number:{storm_number}'\n",
    "    with open(f'/work/FAC/FGSE/IDYST/tbeucler/default/fabien/repos/curnagl/datasets_3h/processing_log_3h.txt', 'a') as log_file:\n",
    "        log_file.write(log_message + '\\n')\n",
    "\n",
    "# Main function to process data\n",
    "def process_data(variable, year, level=0):\n",
    "    year = int(year)\n",
    "    year_next = year + 1\n",
    "    month_act = [10, 11, 12]\n",
    "    month_next = [1, 2, 3]\n",
    "    if variable == 'geopotential':\n",
    "        way = '/work/FAC/FGSE/IDYST/tbeucler/default/raw_data/ECMWF/ERA5_hourly_PL/'\n",
    "    else:\n",
    "        way = '/work/FAC/FGSE/IDYST/tbeucler/default/raw_data/ECMWF/ERA5/SL/'\n",
    "\n",
    "    # Open and concatenate datasets\n",
    "    if year == 1990:\n",
    "        dataset_act = open_and_concatenate(str(year), variable, month_next, way, level)\n",
    "        dataset_next = open_and_concatenate(str(year_next), variable, month_next, way, level)\n",
    "        dataset = xr.concat([dataset_act, dataset_next], dim='time')\n",
    "        dataset = dataset.chunk({'time': 10})\n",
    "    elif year == 2021:\n",
    "        dataset = open_and_concatenate(str(year), variable, month_next, way, level)\n",
    "    else:\n",
    "        dataset_act = open_and_concatenate(str(year), variable, month_act, way, level)\n",
    "        dataset_next = open_and_concatenate(str(year_next), variable, month_next, way, level)\n",
    "        dataset = xr.concat([dataset_act, dataset_next], dim='time')\n",
    "        dataset = dataset.chunk({'time': 10})\n",
    "\n",
    "    # Determine the specific variable to extract\n",
    "    specific_var = next(var for var in dataset.variables if var not in ['longitude', 'latitude', 'time', 'level'])\n",
    "\n",
    "    # Import all tracks and convert dates\n",
    "    dates = pd.read_csv(f'/work/FAC/FGSE/IDYST/tbeucler/default/fabien/repos/curnagl/storms_start_end.csv', parse_dates=['start_date', 'end_date'])\n",
    "    dates['year'] = dates['start_date'].dt.year\n",
    "\n",
    "    # Find the indices for storms within the specified timeframe\n",
    "    if year == 1990:\n",
    "        index_start_october = dates[(dates['start_date'].dt.month <= 3) & (dates['start_date'].dt.year == year)].index[0]\n",
    "        index_end_march = dates[(dates['end_date'].dt.month <= 3) & (dates['end_date'].dt.year == year_next)].index[0]\n",
    "    elif year == 2021:\n",
    "        index_start_october = dates[(dates['start_date'].dt.month <= 3) & (dates['start_date'].dt.year == year)].index[0]\n",
    "        index_end_march = dates[(dates['end_date'].dt.year == 2021)].index[0]\n",
    "    else:\n",
    "    # Chercher start_october dans year, sinon chercher dès janvier de year_next\n",
    "        index_start_october = dates[((dates['start_date'].dt.month >= 10) & (dates['start_date'].dt.year == year)) | ((dates['start_date'].dt.year == year_next) & (dates['start_date'].dt.month >= 1))].index[0]\n",
    "        index_end_march_first = dates[((dates['end_date'].dt.month <= 3) & (dates['end_date'].dt.year == year_next))].index\n",
    "        #print(index_start_october, index_end_march_first, '3rd condition start_october + index_end_march_first')\n",
    "        if len(index_end_march_first) > 0:\n",
    "            index_end_march = index_end_march_first[-1]\n",
    "            #print(index_end_march, 'index_end_march 1st condition of 2nd condition')\n",
    "        else:\n",
    "            # Si year_next ne renvoie rien, chercher la dernière instance de tempête dans year\n",
    "            index_end_march = dates[((dates['end_date'].dt.year == year) & (dates['end_date'].dt.month <= 12))].index[-1]\n",
    "            #print(index_end_march, 'index_end_march 2nd condition of 2nd condition')\n",
    "    # Process each storm\n",
    "    for i in range(index_start_october, index_end_march + 1):\n",
    "        track = pd.read_csv(f'/work/FAC/FGSE/IDYST/tbeucler/default/fabien/repos/curnagl/tc_irad_tracks/tc_3_hours/tc_irad_{i+1}.txt')\n",
    "        start_date = dates.at[i, 'start_date']\n",
    "        end_date = dates.at[i, 'end_date']\n",
    "        storm_data = dataset[specific_var].sel(time=slice(start_date, end_date))\n",
    "\n",
    "        # Initialize lists to store statistics\n",
    "        stats = {'mean': [], 'min': [], 'max': [], 'std': []}\n",
    "        #, 'skewness': [], 'kurtosis': []\n",
    "\n",
    "        # Calculate statistics for each time step\n",
    "        for time_step in storm_data.time:\n",
    "            data_slice = storm_data.sel(time=time_step).values\n",
    "            step_stats = calculate_statistics(data_slice)\n",
    "            for key in stats:\n",
    "                stats[key].append(step_stats[key])\n",
    "\n",
    "        # Save statistics to CSV files\n",
    "        for key in stats:\n",
    "            pd.DataFrame(stats[key]).to_csv(f'/work/FAC/FGSE/IDYST/tbeucler/default/fabien/repos/curnagl/datasets_3h/{variable}/storm_{i+1}/{key}_{i+1}_{level}.csv')\n",
    "\n",
    "    # Log the processing details\n",
    "    log_processing(variable, year, level, i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = 'geopotential'\n",
    "year = sys.argv[2]\n",
    "level = sys.argv[3]\n",
    "process_data(variable, year, level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2005\n",
    "variable = 'geopotential'\n",
    "months = [1, 2, 3]\n",
    "way = '/work/FAC/FGSE/IDYST/tbeucler/default/raw_data/ECMWF/ERA5_hourly_PL/'\n",
    "level = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_open = open_and_concatenate(year, variable, months, way, level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt;\n",
       "Dimensions:    (longitude: 1440, latitude: 721, time: 720)\n",
       "Coordinates:\n",
       "  * longitude  (longitude) float32 0.0 0.25 0.5 0.75 ... 359.0 359.2 359.5 359.8\n",
       "  * latitude   (latitude) float32 90.0 89.75 89.5 89.25 ... -89.5 -89.75 -90.0\n",
       "    level      int32 1000\n",
       "  * time       (time) datetime64[ns] 2005-01-01 ... 2005-03-31T21:00:00\n",
       "Data variables:\n",
       "    z          (time, latitude, longitude) float32 1.204e+03 1.204e+03 ... 271.1\n",
       "Attributes:\n",
       "    Conventions:  CF-1.6\n",
       "    history:      2024-05-12 04:34:52 GMT by grib_to_netcdf-2.28.1: /opt/ecmw...</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-644ae5fb-b49f-44cd-890f-c2e9f45f8fc5' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-644ae5fb-b49f-44cd-890f-c2e9f45f8fc5' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>longitude</span>: 1440</li><li><span class='xr-has-index'>latitude</span>: 721</li><li><span class='xr-has-index'>time</span>: 720</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-7ab1b6f2-1037-4dc7-8fdc-8838a0fe5371' class='xr-section-summary-in' type='checkbox'  checked><label for='section-7ab1b6f2-1037-4dc7-8fdc-8838a0fe5371' class='xr-section-summary' >Coordinates: <span>(4)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>longitude</span></div><div class='xr-var-dims'>(longitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>0.0 0.25 0.5 ... 359.2 359.5 359.8</div><input id='attrs-5da5eb08-1da8-495b-b843-f2fe409219e0' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-5da5eb08-1da8-495b-b843-f2fe409219e0' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-56e52ea5-4bdf-42f6-866d-654864ebc2ae' class='xr-var-data-in' type='checkbox'><label for='data-56e52ea5-4bdf-42f6-866d-654864ebc2ae' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>degrees_east</dd><dt><span>long_name :</span></dt><dd>longitude</dd></dl></div><div class='xr-var-data'><pre>array([0.0000e+00, 2.5000e-01, 5.0000e-01, ..., 3.5925e+02, 3.5950e+02,\n",
       "       3.5975e+02], dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>latitude</span></div><div class='xr-var-dims'>(latitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>90.0 89.75 89.5 ... -89.75 -90.0</div><input id='attrs-203dc0a5-f63b-492d-b554-868ef2de7075' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-203dc0a5-f63b-492d-b554-868ef2de7075' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-cf9a5f93-8591-484b-835b-a3a28556517c' class='xr-var-data-in' type='checkbox'><label for='data-cf9a5f93-8591-484b-835b-a3a28556517c' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>degrees_north</dd><dt><span>long_name :</span></dt><dd>latitude</dd></dl></div><div class='xr-var-data'><pre>array([ 90.  ,  89.75,  89.5 , ..., -89.5 , -89.75, -90.  ], dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>level</span></div><div class='xr-var-dims'>()</div><div class='xr-var-dtype'>int32</div><div class='xr-var-preview xr-preview'>1000</div><input id='attrs-26b6f37b-bce6-407d-b1f5-b6cf32cc8c23' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-26b6f37b-bce6-407d-b1f5-b6cf32cc8c23' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-0a05ecfe-6593-410b-8090-5490eff43be4' class='xr-var-data-in' type='checkbox'><label for='data-0a05ecfe-6593-410b-8090-5490eff43be4' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>millibars</dd><dt><span>long_name :</span></dt><dd>pressure_level</dd></dl></div><div class='xr-var-data'><pre>array(1000, dtype=int32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>2005-01-01 ... 2005-03-31T21:00:00</div><input id='attrs-690650d4-3572-47a3-adc9-f038d7730c10' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-690650d4-3572-47a3-adc9-f038d7730c10' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-488823fb-09c8-42a0-83db-03451e6b90cb' class='xr-var-data-in' type='checkbox'><label for='data-488823fb-09c8-42a0-83db-03451e6b90cb' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>time</dd></dl></div><div class='xr-var-data'><pre>array([&#x27;2005-01-01T00:00:00.000000000&#x27;, &#x27;2005-01-01T03:00:00.000000000&#x27;,\n",
       "       &#x27;2005-01-01T06:00:00.000000000&#x27;, ..., &#x27;2005-03-31T15:00:00.000000000&#x27;,\n",
       "       &#x27;2005-03-31T18:00:00.000000000&#x27;, &#x27;2005-03-31T21:00:00.000000000&#x27;],\n",
       "      dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-f8e8b0f1-114d-4254-a263-8ad4a81bd98c' class='xr-section-summary-in' type='checkbox'  checked><label for='section-f8e8b0f1-114d-4254-a263-8ad4a81bd98c' class='xr-section-summary' >Data variables: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>z</span></div><div class='xr-var-dims'>(time, latitude, longitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>1.204e+03 1.204e+03 ... 271.1 271.1</div><input id='attrs-fb531949-e040-423e-8328-76e70404bfb6' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-fb531949-e040-423e-8328-76e70404bfb6' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-91cc946f-6f6d-4ed0-b5fe-81bd18863fab' class='xr-var-data-in' type='checkbox'><label for='data-91cc946f-6f6d-4ed0-b5fe-81bd18863fab' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>m**2 s**-2</dd><dt><span>long_name :</span></dt><dd>Geopotential</dd><dt><span>standard_name :</span></dt><dd>geopotential</dd></dl></div><div class='xr-var-data'><pre>array([[[1204.4727 , 1204.4727 , 1204.4727 , ..., 1204.4727 ,\n",
       "         1204.4727 , 1204.4727 ],\n",
       "        [1159.9414 , 1159.9414 , 1159.9414 , ..., 1160.9102 ,\n",
       "         1160.9102 , 1159.9414 ],\n",
       "        [1113.4727 , 1112.5059 , 1112.5059 , ..., 1113.4727 ,\n",
       "         1113.4727 , 1113.4727 ],\n",
       "        ...,\n",
       "        [ 273.1797 ,  273.1797 ,  273.1797 , ...,  273.1797 ,\n",
       "          273.1797 ,  273.1797 ],\n",
       "        [ 274.14844,  274.14844,  274.14844, ...,  274.14844,\n",
       "          274.14844,  274.14844],\n",
       "        [ 276.08398,  276.08398,  276.08398, ...,  276.08398,\n",
       "          276.08398,  276.08398]],\n",
       "\n",
       "       [[1219.9629 , 1219.9629 , 1219.9629 , ..., 1219.9629 ,\n",
       "         1219.9629 , 1219.9629 ],\n",
       "        [1181.2383 , 1181.2383 , 1181.2383 , ..., 1181.2383 ,\n",
       "         1181.2383 , 1181.2383 ],\n",
       "        [1139.6113 , 1139.6113 , 1139.6113 , ..., 1140.5801 ,\n",
       "         1140.5801 , 1140.5801 ],\n",
       "...\n",
       "        [ 386.39062,  385.42188,  383.48438, ...,  391.23242,\n",
       "          389.29492,  388.32617],\n",
       "        [ 285.67188,  284.70312,  284.70312, ...,  288.57617,\n",
       "          287.60742,  286.64062],\n",
       "        [ 269.20703,  269.20703,  269.20703, ...,  269.20703,\n",
       "          269.20703,  269.20703]],\n",
       "\n",
       "       [[ 847.37305,  847.37305,  847.37305, ...,  847.37305,\n",
       "          847.37305,  847.37305],\n",
       "        [ 864.8047 ,  864.8047 ,  864.8047 , ...,  865.77344,\n",
       "          864.8047 ,  864.8047 ],\n",
       "        [ 878.3633 ,  878.3633 ,  878.3633 , ...,  879.33203,\n",
       "          878.3633 ,  878.3633 ],\n",
       "        ...,\n",
       "        [ 373.80078,  372.83203,  370.89453, ...,  378.64258,\n",
       "          376.70508,  375.73633],\n",
       "        [ 280.82812,  279.86133,  278.89258, ...,  282.76562,\n",
       "          281.79688,  280.82812],\n",
       "        [ 271.14453,  271.14453,  271.14453, ...,  271.14453,\n",
       "          271.14453,  271.14453]]], dtype=float32)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-37cf4eac-f2a7-4ffb-8db4-9bf5392ebf1a' class='xr-section-summary-in' type='checkbox'  ><label for='section-37cf4eac-f2a7-4ffb-8db4-9bf5392ebf1a' class='xr-section-summary' >Indexes: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>longitude</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-c3f251e5-fda8-4d6e-876f-7c83370a5a1a' class='xr-index-data-in' type='checkbox'/><label for='index-c3f251e5-fda8-4d6e-876f-7c83370a5a1a' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([   0.0,   0.25,    0.5,   0.75,    1.0,   1.25,    1.5,   1.75,    2.0,\n",
       "         2.25,\n",
       "       ...\n",
       "        357.5, 357.75,  358.0, 358.25,  358.5, 358.75,  359.0, 359.25,  359.5,\n",
       "       359.75],\n",
       "      dtype=&#x27;float32&#x27;, name=&#x27;longitude&#x27;, length=1440))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>latitude</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-20beb2ad-21e5-4cae-9b39-b057fe285897' class='xr-index-data-in' type='checkbox'/><label for='index-20beb2ad-21e5-4cae-9b39-b057fe285897' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([  90.0,  89.75,   89.5,  89.25,   89.0,  88.75,   88.5,  88.25,   88.0,\n",
       "        87.75,\n",
       "       ...\n",
       "       -87.75,  -88.0, -88.25,  -88.5, -88.75,  -89.0, -89.25,  -89.5, -89.75,\n",
       "        -90.0],\n",
       "      dtype=&#x27;float32&#x27;, name=&#x27;latitude&#x27;, length=721))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>time</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-0857cc5f-cfd9-4c19-b22a-5bfe42a41dfa' class='xr-index-data-in' type='checkbox'/><label for='index-0857cc5f-cfd9-4c19-b22a-5bfe42a41dfa' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(DatetimeIndex([&#x27;2005-01-01 00:00:00&#x27;, &#x27;2005-01-01 03:00:00&#x27;,\n",
       "               &#x27;2005-01-01 06:00:00&#x27;, &#x27;2005-01-01 09:00:00&#x27;,\n",
       "               &#x27;2005-01-01 12:00:00&#x27;, &#x27;2005-01-01 15:00:00&#x27;,\n",
       "               &#x27;2005-01-01 18:00:00&#x27;, &#x27;2005-01-01 21:00:00&#x27;,\n",
       "               &#x27;2005-01-02 00:00:00&#x27;, &#x27;2005-01-02 03:00:00&#x27;,\n",
       "               ...\n",
       "               &#x27;2005-03-30 18:00:00&#x27;, &#x27;2005-03-30 21:00:00&#x27;,\n",
       "               &#x27;2005-03-31 00:00:00&#x27;, &#x27;2005-03-31 03:00:00&#x27;,\n",
       "               &#x27;2005-03-31 06:00:00&#x27;, &#x27;2005-03-31 09:00:00&#x27;,\n",
       "               &#x27;2005-03-31 12:00:00&#x27;, &#x27;2005-03-31 15:00:00&#x27;,\n",
       "               &#x27;2005-03-31 18:00:00&#x27;, &#x27;2005-03-31 21:00:00&#x27;],\n",
       "              dtype=&#x27;datetime64[ns]&#x27;, name=&#x27;time&#x27;, length=720, freq=None))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-34b87b0f-c786-4ab6-8d22-c4a8fd768981' class='xr-section-summary-in' type='checkbox'  checked><label for='section-34b87b0f-c786-4ab6-8d22-c4a8fd768981' class='xr-section-summary' >Attributes: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>Conventions :</span></dt><dd>CF-1.6</dd><dt><span>history :</span></dt><dd>2024-05-12 04:34:52 GMT by grib_to_netcdf-2.28.1: /opt/ecmwf/mars-client/bin/grib_to_netcdf -S param -o /cache/data9/adaptor.mars.internal-1715488472.0196917-21473-9-86843623-1caf-44fd-b16f-f3aa097e4e0b.nc /cache/tmp/86843623-1caf-44fd-b16f-f3aa097e4e0b-adaptor.mars.internal-1715488380.23027-21473-6-tmp.grib</dd></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:    (longitude: 1440, latitude: 721, time: 720)\n",
       "Coordinates:\n",
       "  * longitude  (longitude) float32 0.0 0.25 0.5 0.75 ... 359.0 359.2 359.5 359.8\n",
       "  * latitude   (latitude) float32 90.0 89.75 89.5 89.25 ... -89.5 -89.75 -90.0\n",
       "    level      int32 1000\n",
       "  * time       (time) datetime64[ns] 2005-01-01 ... 2005-03-31T21:00:00\n",
       "Data variables:\n",
       "    z          (time, latitude, longitude) float32 1.204e+03 1.204e+03 ... 271.1\n",
       "Attributes:\n",
       "    Conventions:  CF-1.6\n",
       "    history:      2024-05-12 04:34:52 GMT by grib_to_netcdf-2.28.1: /opt/ecmw..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "\n",
    "for month in months:\n",
    "    dataset = xr.open_dataset(f'{way}{variable}/ERA5_{year}-{month}_{variable}.nc')\n",
    "    if variable == 'geopotential' and level != 0:\n",
    "        dataset = dataset.sel(level=level)\n",
    "    \n",
    "    # Create a date range with 3-hour intervals starting from midnight\n",
    "    start = pd.Timestamp(f\"{year}-{month}-01 00:00:00\")\n",
    "    if month == 12:\n",
    "        end = pd.date_range(start=f\"{year}-{month}-01\", end=f\"{str(int(year)+1)}-01-01\", freq='M')[0] + pd.Timedelta(hours=21)\n",
    "    else:\n",
    "        end = pd.date_range(start=f\"{year}-{month}-01\", end=f\"{year}-{month+1}-01\", freq='M')[0] + pd.Timedelta(hours=21)\n",
    "    date_range = pd.date_range(start, end, freq='3H')\n",
    "\n",
    "    # Select the data at the specific timesteps\n",
    "    dataset = dataset.sel(time=date_range)\n",
    "    \n",
    "    datasets.append(dataset)\n",
    "    dataset.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 7 1st condition of 1990\n"
     ]
    }
   ],
   "source": [
    "test_2 = process_data(variable, year, level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = int(year)\n",
    "year_next = year + 1\n",
    "month_act = [10, 11, 12]\n",
    "month_next = [1, 2, 3]\n",
    "if variable == 'geopotential':\n",
    "    way = '/work/FAC/FGSE/IDYST/tbeucler/default/raw_data/ECMWF/ERA5_hourly_PL/'\n",
    "else:\n",
    "    way = '/work/FAC/FGSE/IDYST/tbeucler/default/raw_data/ECMWF/ERA5/SL/'\n",
    "\n",
    "# Open and concatenate datasets\n",
    "if year == 1990:\n",
    "    dataset_act = open_and_concatenate(str(year), variable, month_next, way, level)\n",
    "    dataset_next = open_and_concatenate(str(year_next), variable, month_next, way, level)\n",
    "    dataset = xr.concat([dataset_act, dataset_next], dim='time')\n",
    "    dataset = dataset.chunk({'time': 10})\n",
    "elif year == 2021:\n",
    "    dataset = open_and_concatenate(str(year), variable, month_next, way, level)\n",
    "else:\n",
    "    dataset_act = open_and_concatenate(str(year), variable, month_act, way, level)\n",
    "    dataset_next = open_and_concatenate(str(year_next), variable, month_next, way, level)\n",
    "    dataset = xr.concat([dataset_act, dataset_next], dim='time')\n",
    "    dataset = dataset.chunk({'time': 10})\n",
    "\n",
    "# Determine the specific variable to extract\n",
    "specific_var = next(var for var in dataset.variables if var not in ['longitude', 'latitude', 'time', 'level'])\n",
    "\n",
    "# Import all tracks and convert dates\n",
    "dates = pd.read_csv(f'/work/FAC/FGSE/IDYST/tbeucler/default/fabien/repos/curnagl/storms_start_end.csv', parse_dates=['start_date', 'end_date'])\n",
    "dates['year'] = dates['start_date'].dt.year\n",
    "\n",
    "# Find the indices for storms within the specified timeframe\n",
    "if year == 1990:\n",
    "    index_start_october = dates[(dates['start_date'].dt.month <= 3) & (dates['start_date'].dt.year == year)].index[0]\n",
    "    index_end_march = dates[(dates['end_date'].dt.month <= 3) & (dates['end_date'].dt.year == year_next)].index[0]\n",
    "elif year == 2021:\n",
    "    index_start_october = dates[(dates['start_date'].dt.month <= 3) & (dates['start_date'].dt.year == year)].index[0]\n",
    "    index_end_march = dates[(dates['end_date'].dt.year == 2021)].index[0]\n",
    "else:\n",
    "# Chercher start_october dans year, sinon chercher dès janvier de year_next\n",
    "    index_start_october = dates[((dates['start_date'].dt.month >= 10) & (dates['start_date'].dt.year == year)) | ((dates['start_date'].dt.year == year_next) & (dates['start_date'].dt.month >= 1))].index[0]\n",
    "    index_end_march_first = dates[((dates['end_date'].dt.month <= 3) & (dates['end_date'].dt.year == year_next))].index\n",
    "    #print(index_start_october, index_end_march_first, '3rd condition start_october + index_end_march_first')\n",
    "    if len(index_end_march_first) > 0:\n",
    "        index_end_march = index_end_march_first[-1]\n",
    "        #print(index_end_march, 'index_end_march 1st condition of 2nd condition')\n",
    "    else:\n",
    "        # Si year_next ne renvoie rien, chercher la dernière instance de tempête dans year\n",
    "        index_end_march = dates[((dates['end_date'].dt.year == year) & (dates['end_date'].dt.month <= 12))].index[-1]\n",
    "        #print(index_end_march, 'index_end_march 2nd condition of 2nd condition')\n",
    "# Process each storm\n",
    "for i in range(index_start_october, index_end_march + 1):\n",
    "    track = pd.read_csv(f'/work/FAC/FGSE/IDYST/tbeucler/default/fabien/repos/curnagl/tc_irad_tracks/tc_3_hours/tc_irad_{i+1}.txt')\n",
    "    start_date = dates.at[i, 'start_date']\n",
    "    end_date = dates.at[i, 'end_date']\n",
    "    storm_data = dataset[specific_var].sel(time=slice(start_date, end_date))\n",
    "\n",
    "    # Initialize lists to store statistics\n",
    "    stats = {'mean': [], 'min': [], 'max': [], 'std': []}\n",
    "    #, 'skewness': [], 'kurtosis': []\n",
    "\n",
    "    # Calculate statistics for each time step\n",
    "    for time_step in storm_data.time:\n",
    "        data_slice = storm_data.sel(time=time_step).values\n",
    "        step_stats = calculate_statistics(data_slice)\n",
    "        for key in stats:\n",
    "            stats[key].append(step_stats[key])\n",
    "\n",
    "    # Save statistics to CSV files\n",
    "    for key in stats:\n",
    "        pd.DataFrame(stats[key]).to_csv(f'/work/FAC/FGSE/IDYST/tbeucler/default/fabien/repos/curnagl/datasets_3h/{variable}/storm_{i+1}/{key}_{i+1}_{level}.csv')\n",
    "\n",
    "# Log the processing details\n",
    "log_processing(variable, year, level, i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition of a set of 556294 objects. Total size = 73990366 bytes.\n",
      " Index  Count   %     Size   % Cumulative  % Kind (class / dict of class)\n",
      "     0 157869  28 22672432  31  22672432  31 str\n",
      "     1 129855  23  9451928  13  32124360  43 tuple\n",
      "     2  38668   7  6867073   9  38991433  53 types.CodeType\n",
      "     3  19704   4  5742824   8  44734257  60 dict (no owner)\n",
      "     4  72160  13  5683431   8  50417688  68 bytes\n",
      "     5  34732   6  4723552   6  55141240  75 function\n",
      "     6   4408   1  4156480   6  59297720  80 type\n",
      "     7   1605   0  2554920   3  61852640  84 dict of module\n",
      "     8   4408   1  2273688   3  64126328  87 dict of type\n",
      "     9   1655   0   905064   1  65031392  88 set\n",
      "<1379 more rows. Type e.g. '_.more' to view.>\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from guppy import hpy\n",
    "\n",
    "# Créer une instance de heapy\n",
    "hp = hpy()\n",
    "# might be a problem for ML data, since the data is quite large in size\n",
    "# Define a function to open datasets and concatenate them\n",
    "def open_and_concatenate(year, variable, months, way, level=0):\n",
    "    datasets = [xr.open_dataset(f'{way}{variable}/ERA5_{year}-{month}_{variable}.nc') for month in months]\n",
    "    if variable == 'geopotential' and level != 0:\n",
    "        datasets = [dataset.sel(level=level) for dataset in datasets]\n",
    "    return xr.concat(datasets, dim='time')\n",
    "\n",
    "# Define a function to calculate statistics\n",
    "def calculate_statistics(data_array):\n",
    "    return {\n",
    "        'mean': np.mean(data_array),\n",
    "        'min': np.min(data_array),\n",
    "        'max': np.max(data_array),\n",
    "        'std': np.std(data_array),\n",
    "    }\n",
    "\n",
    "# Function to log processing details\n",
    "def log_processing(variable, year, level, storm_number):\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    log_message = f'Processed variable: {variable}, Year: {year}, Level: {level}, Timestamp: {timestamp}, Storm number:{storm_number}'\n",
    "    with open(f'/work/FAC/FGSE/IDYST/tbeucler/default/fabien/repos/curnagl/datasets/processing_log.txt', 'a') as log_file:\n",
    "        log_file.write(log_message + '\\n')\n",
    "\n",
    "# Créer une instance de heapy\n",
    "hp = hpy()\n",
    "\n",
    "# Main function to process data\n",
    "def process_data(variable, year, level=0):\n",
    "    year = int(year)\n",
    "    year_next = year + 1\n",
    "    month_act = [10, 11, 12]\n",
    "    month_next = [1, 2, 3]\n",
    "    if variable == 'geopotential':\n",
    "        way = '/work/FAC/FGSE/IDYST/tbeucler/default/raw_data/ECMWF/ERA5_hourly_PL/'\n",
    "    else:\n",
    "        way = '/work/FAC/FGSE/IDYST/tbeucler/default/raw_data/ECMWF/ERA5/SL/'\n",
    "\n",
    "    # Open and concatenate datasets\n",
    "    if year == 1990:\n",
    "        dataset_act = open_and_concatenate(str(year), variable, month_next, way, level)\n",
    "        dataset_next = open_and_concatenate(str(year_next), variable, month_next, way, level)\n",
    "        dataset = xr.concat([dataset_act, dataset_next], dim='time')\n",
    "        dataset = dataset.chunk({'time': 10})\n",
    "    elif year == 2021:\n",
    "        dataset = open_and_concatenate(str(year), variable, month_next, way, level)\n",
    "    else:\n",
    "        dataset_act = open_and_concatenate(str(year), variable, month_act, way, level)\n",
    "        dataset_next = open_and_concatenate(str(year_next), variable, month_next, way, level)\n",
    "        dataset = xr.concat([dataset_act, dataset_next], dim='time')\n",
    "        dataset = dataset.chunk({'time': 10})\n",
    "\n",
    "    # Determine the specific variable to extract\n",
    "    specific_var = next(var for var in dataset.variables if var not in ['longitude', 'latitude', 'time', 'level'])\n",
    "\n",
    "    # Import all tracks and convert dates\n",
    "    dates = pd.read_csv(f'/work/FAC/FGSE/IDYST/tbeucler/default/fabien/repos/curnagl/storms_start_end.csv', parse_dates=['start_date', 'end_date'])\n",
    "    dates['year'] = dates['start_date'].dt.year\n",
    "\n",
    "    # Find the indices for storms within the specified timeframe\n",
    "    if year == 1990:\n",
    "        index_start_october = dates[(dates['start_date'].dt.month <= 3) & (dates['start_date'].dt.year == year)].index[0]\n",
    "        index_end_march = dates[(dates['end_date'].dt.month <= 3) & (dates['end_date'].dt.year == year_next)].index[0]\n",
    "    elif year == 2021:\n",
    "        index_start_october = dates[(dates['start_date'].dt.month <= 3) & (dates['start_date'].dt.year == year)].index[0]\n",
    "        index_end_march = dates[(dates['end_date'].dt.year == 2021)].index[0]\n",
    "    else:\n",
    "    # Chercher start_october dans year, sinon chercher dès janvier de year_next\n",
    "        index_start_october = dates[((dates['start_date'].dt.month >= 10) & (dates['start_date'].dt.year == year)) | ((dates['start_date'].dt.year == year_next) & (dates['start_date'].dt.month >= 1))].index[0]\n",
    "        index_end_march_first = dates[((dates['end_date'].dt.month <= 3) & (dates['end_date'].dt.year == year_next))].index\n",
    "        #print(index_start_october, index_end_march_first, '3rd condition start_october + index_end_march_first')\n",
    "        if len(index_end_march_first) > 0:\n",
    "            index_end_march = index_end_march_first[-1]\n",
    "            #print(index_end_march, 'index_end_march 1st condition of 2nd condition')\n",
    "        else:\n",
    "            # Si year_next ne renvoie rien, chercher la dernière instance de tempête dans year\n",
    "            index_end_march = dates[((dates['end_date'].dt.year == year) & (dates['end_date'].dt.month <= 12))].index[-1]\n",
    "            #print(index_end_march, 'index_end_march 2nd condition of 2nd condition')\n",
    "    # Process each storm\n",
    "    for i in range(index_start_october, index_end_march + 1):\n",
    "        track = pd.read_csv(f'/work/FAC/FGSE/IDYST/tbeucler/default/fabien/repos/curnagl/tc_irad_tracks/tc_1_hour/tc_irad_{i+1}_interp.txt')\n",
    "        start_date = dates.at[i, 'start_date']\n",
    "        end_date = dates.at[i, 'end_date']\n",
    "        storm_data = dataset[specific_var].sel(time=slice(start_date, end_date))\n",
    "\n",
    "        # Initialize lists to store statistics\n",
    "        stats = {'mean': [], 'min': [], 'max': [], 'std': []}\n",
    "        #, 'skewness': [], 'kurtosis': []\n",
    "\n",
    "        # Calculate statistics for each time step\n",
    "        for time_step in storm_data.time:\n",
    "            data_slice = storm_data.sel(time=time_step).values\n",
    "            step_stats = calculate_statistics(data_slice)\n",
    "            for key in stats:\n",
    "                stats[key].append(step_stats[key])\n",
    "\n",
    "        # Save statistics to CSV files\n",
    "        for key in stats:\n",
    "            pd.DataFrame(stats[key]).to_csv(f'/work/FAC/FGSE/IDYST/tbeucler/default/fabien/repos/curnagl/datasets/{variable}/storm_{i+1}/{key}_{i+1}_{level}.csv')\n",
    "\n",
    "    # Log the processing details\n",
    "    log_processing(variable, year, level, i+1)\n",
    "\n",
    "# Obtenir un instantané de l'utilisation de la mémoire\n",
    "h = hp.heap()\n",
    "\n",
    "# Imprimer l'information d'utilisation de la mémoire\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_3 = process_data('10m_v_component_of_wind', 2020, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
